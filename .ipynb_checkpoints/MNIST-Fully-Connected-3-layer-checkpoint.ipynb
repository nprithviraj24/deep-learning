{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image at index 3: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "y = np.matrix(digits.target).T\n",
    "X = np.matrix(digits.data)\n",
    "print(\"Image at index 3: \")\n",
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[3]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes of data:  ['data', 'target', 'target_names', 'images', 'DESCR']\n",
      "Label of an image:  3\n"
     ]
    }
   ],
   "source": [
    "M = X.shape[0]\n",
    "N = X.shape[1]\n",
    "# N\n",
    "# list(digits.data[0].shape)\n",
    "# X\n",
    "attributes = list(digits)\n",
    "print(\"Attributes of data: \", attributes)\n",
    "print(\"Label of an image: \", digits.target[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to one hot encode the outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Let's start with a 3-layer network with sigmoid activation functions,\n",
    "# 6 units in layer 1, and 5 units in layer 2.\n",
    "\n",
    "h2 = 16\n",
    "h1 = 32\n",
    "W = [[], np.random.normal(0,0.1,[N,h1]),\n",
    "         np.random.normal(0,0.1,[h1,h2]),\n",
    "         np.random.normal(0,0.1,[h2,10])]\n",
    "b = [[], np.random.normal(0,0.1,[h1,1]),\n",
    "         np.random.normal(0,0.1,[h2,1]),\n",
    "         np.random.normal(0,0.1,[10,1])]\n",
    "L = len(W)-1\n",
    "print(L)\n",
    "# def act(z):\n",
    "#     return z if z>0 else 0\n",
    "# def actder(z):\n",
    "#     return 1 if z>0 else 0\n",
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "def relu_der(z):\n",
    "    x[x<=0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "def softmax_grad(x):\n",
    "    prob = softmax(x)\n",
    "    return np.multiply(prob, (1-prob))\n",
    "    # Reshape the 1-d softmax to 2-d so that np.dot will do the matrix multiplication\n",
    "#     s = softmax.reshape(-1,1)\n",
    "#     return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "def delta_cross_entropy(y, X):\n",
    "    m = y.shape[0]\n",
    "    grad = softmax(X)\n",
    "#     grad = X\n",
    "    idx = np.where(grad == y*grad)\n",
    "    grad[idx] = grad[idx] - 1\n",
    "    grad = grad/m\n",
    "    return grad\n",
    "\n",
    "# def softmax(X)\n",
    "# y = np.matrix([1,0,2])\n",
    "# X = np.matrix([2,4,1])\n",
    "# print(delta_cross_entropy(y.T,X))\n",
    "# print(softmax(np.array([1,2,3])))\n",
    "# img = images[img_idx]\n",
    "# helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ff(x,W,b):\n",
    "    L = len(W)-1\n",
    "    a = x\n",
    "    for l in range(1,L+1):\n",
    "        z = W[l].T*a+b[l]\n",
    "        a = act(z)\n",
    "    return a\n",
    "\n",
    "def loss(y,yhat):\n",
    "    return y-yhat \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backpropogation\n",
      "<class 'numpy.matrix'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-3b5319de67dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mdW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_der\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-95-c30ab1886166>\u001b[0m in \u001b[0;36mrelu_der\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrelu_der\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "   \n",
    "# Use mini-batch size 1\n",
    "\n",
    "alpha = 0.01\n",
    "#originally max-iter = 1000\n",
    "max_iter = 2\n",
    "\n",
    "for iter in range(0, max_iter):\n",
    "    loss_this_iter = 0\n",
    "    order = np.random.permutation(M)\n",
    "    for i in range(0,M):\n",
    "        \n",
    "        # Grab the pattern order[i]\n",
    "        \n",
    "        x_this = X[order[i],:].T\n",
    "        y_this = y[order[i],0]\n",
    "        yt = np.matrix([np.zeros(10)]).T\n",
    "#         print(yt.shape, y_this)\n",
    "        yt[y_this] = 1\n",
    "#         print(yt)\n",
    "        # Feed forward step\n",
    "        \n",
    "        a = [x_this]\n",
    "        z = [[]]\n",
    "        delta = [[]]\n",
    "        dW = [[]]\n",
    "        db = [[]]\n",
    "#         for l in range(1,L+1):\n",
    "#             print(\"a-l: \", l-1,\"  actual l: \", l)\n",
    "        layer =1\n",
    "        #First layer\n",
    "        z.append(W[layer].T*a[layer-1]+b[layer])\n",
    "        a.append(relu(z[-1]))\n",
    "        delta.append([]); dW.append([]); db.append([])\n",
    "#         print(\"z shape at end of 1st layer:\", z[-1].shape)        \n",
    "#         print(\"a shape at end of 1st layer:\", a[-1].shape)\n",
    "\n",
    "        layer=2\n",
    "        #Second layer\n",
    "        z.append(W[layer].T*a[layer-1]+b[layer])\n",
    "        a.append(relu(z[-1]))\n",
    "        delta.append([]); dW.append([]); db.append([])\n",
    "        \n",
    "#         print(\"z shape at end of 2nd layer:\", z[-1].shape)        \n",
    "#         print(\"a shape at end of 2nd layer:\", a[-1].shape)\n",
    "\n",
    "        layer=3\n",
    "        #third layer\n",
    "        z.append(W[layer].T*a[layer-1]+b[layer])\n",
    "        a.append(softmax(z[-1]))\n",
    "        delta.append([]); dW.append([]); db.append([])\n",
    "        \n",
    "#         print(\"z shape at end of 3rd layer:\", z[-1].shape)\n",
    "#         print(a[-1].sum())\n",
    "        \n",
    "        loss_this_pattern = np.sum(np.subtract(yt, a[3]))\n",
    "        loss_this_iter = loss_this_iter + loss_this_pattern\n",
    "            \n",
    "#         # Backprop step\n",
    "\n",
    "#         delta[layer] = np.subtract(yt, a[3])\n",
    "#         print(type(yt))\n",
    "   \n",
    "#         print(\"-----------------------------------------------------------\")\n",
    "        print(\"Backpropogation\")\n",
    "        delta[layer] = delta_cross_entropy(a[-1], yt.T)\n",
    "#         print(delta[layer])\n",
    "        db[layer] = delta[layer].copy()\n",
    "        dW[layer] = a[layer-1] * delta[layer]\n",
    "#         print(dW[layer].shape)\n",
    "        delta[layer-1] = np.multiply(softmax_grad(z[layer-1]), W[layer] * delta[layer].T)\n",
    "#         print(delta[layer].shape)\n",
    "#         print(delta[layer-1].shape)\n",
    "#         print(dW[layer].shape)\n",
    "#         print(softmax_grad(z[layer-1]).shape)\n",
    "        \n",
    "        layer=2\n",
    "        db[layer] = delta[layer].copy()\n",
    "        dW[layer] = a[layer-1] * delta[layer].T\n",
    "        delta[layer-1] = np.multiply(relu_der(z[layer-1]), W[layer] * delta[layer])\n",
    "        \n",
    "        layer=1\n",
    "        db[layer] = delta[layer].copy()\n",
    "        dW[layer] = a[layer-1] * delta[layer].T\n",
    "        delta[layer-1] = np.multiply(relu_der(z[layer-1]), W[layer] * delta[layer])\n",
    "        \n",
    "#         for l in range(L,0,-1):\n",
    "#             print(\"REverse: a -> l: \",l-1, \" actual l: \", l)\n",
    "#             db[l] = delta[l].copy()\n",
    "#             dW[l] = a[l-1] * delta[l].T\n",
    "#             if l > 1:\n",
    "#                 delta[l-1] = np.multiply(actder(z[l-1]), W[l] * delta[l])\n",
    "         #LAYER 3\n",
    "        \n",
    "         \n",
    "                \n",
    "#                  db[l] = delta[l].copy()\n",
    "#             dW[l] = a[l-1] * delta[l].T\n",
    "#             if l > 1:\n",
    "#                 delta[l-1] = np.multiply(actder(z[l-1]), W[l] * delta[l])\n",
    "                \n",
    "#                  db[l] = delta[l].copy()\n",
    "#             dW[l] = a[l-1] * delta[l].T\n",
    "#             if l > 1:\n",
    "#                 delta[l-1] = np.multiply(actder(z[l-1]), W[l] * delta[l])\n",
    "                \n",
    "                \n",
    "#         # Check delta calculation\n",
    "        \n",
    "#         if False:\n",
    "#             print('Target: %f' % y_this)\n",
    "#             print('y_hat: %f' % a[L][0,0])\n",
    "#             print(db)\n",
    "#             y_pred = ff(x_this,W,b)\n",
    "#             diff = 1e-3\n",
    "#             W[1][10,0] = W[1][10,0] + diff\n",
    "#             y_pred_db = ff(x_this,W,b)\n",
    "#             L1 = loss(y_this,y_pred)\n",
    "#             L2 = loss(y_this,y_pred_db)\n",
    "#             db_finite_difference = (L2-L1)/diff\n",
    "#             print('Original out %f, perturbed out %f' %\n",
    "#                  (y_pred[0,0], y_pred_db[0,0]))\n",
    "#             print('Theoretical dW %f, calculated db %f' %\n",
    "#                   (dW[1][10,0], db_finite_difference[0,0]))\n",
    "        \n",
    "#         for l in range(1,L+1):            \n",
    "#             W[l] = W[l] - alpha * dW[l]\n",
    "#             b[l] = b[l] - alpha * db[l]\n",
    "        \n",
    "    print('Iteration %d loss %f' % (iter, loss_this_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
