## Getting started with Machine Learning

I learn by building things, especially in PyTorch.

Following this we will discuss some of the important definitions one should know in ML.




#### What is deep learning?
It is safe to say Machine Learning approach towards building an intelligent system is close to being obsolete. 
Machine learning techniques (in this context, Statistical models) requires a lot of data with selected features beforehand to begin with, 
which can be hectic and tiring job, pardon my paraphrasing. 
 Sure it can be used to develop intelligent systems which can automate lot of tasks.


Providing required parameters and selected features can be abysmal. 
    Deep learning, on the other hand, expects minimal input(s) from the user. It calculates and extracts by itself. It's like a system with a nimble brain.


##### Deep Learning is Neural Networks 
- It is infact a convolutional Neural Network which is aimed to solve computer vision and image classification problems.  
- Deep Learning is a self-taught learning and unsupervised feature extraction and learning.


### Loss function
It is a performance metric on how well the Neural Network manages to reach its goal of generation oupts as close as possible to desired values. 

Example:  <br />
 **loss** = Desired output - Actual output;
 But this is schoolboy stuff, we will most likely work with Sum of squars errors which is notably the most famous loss function in Neural Network.

 <br />
 <strong>Absolute error</strong> It is the result to MOD function applied to an error with a sign or direction.
  <br />
 As a summary, the loss function is an error metric, that gives an indicator on how much precision we lose, if we replace the real desired output by the actual output generated by our trained neural network model. That's why it's called **loss**!

 #### Derivative of error

Our main goal is to optimize the error, and make it as less as possible. There are different techniques and algorithms which adjusts the weights. Since we are dealing with images, we will avoid brute force technique. So one of powerful concept to deal with errors in finding the rate at which error is changing its value at this point ie derivative.
    Derivative of loss function is directly applied on weight(s). 

    Basically it deals with the derivative of the loss function. In mathematics, the derivative of a function at a certain point, gives the rate or the speed of which this function is changing its values at this point.

In order to see the effect of the derivative, we can ask ourselves the following question: 
 how much the total error will change if we change the internal weight of the neural network with a certain small value δW. For the sake of simplicity will consider δW=0.0001. in reality it should be much smaller!.
 
### One might ask how are weights adjusted?
 
    Let OW be the Optimal weight:
        1. If w<OW, we have a positive loss function, but the derivative is negative, meaning 
        that an increase of weight will decrease the loss function.
        
        2. At w=OW, the loss is 0 and the derivative is 0, we reached a perfect model, nothing more 
        is needed.
        
        3. If w>OW, the loss becomes positive again, but the derivative is as well positive, meaning 
        that any more increase in the weight, will increase the losses even more!!
    
#### Convolution :  

When presented with a new image, the CNN doesn’t know exactly where these features will match so it tries them everywhere, in every possible position. In calculating the match to a feature across the whole image, we make it a filter. The math we use to do this is called convolution, from which Convolutional Neural Networks take their name.

The math behind convolution is nothing that would make a sixth-grader uncomfortable. To calculate the match of a feature to a patch of the image, simply multiply each pixel in the feature by the value of the corresponding pixel in the image. Then add up the answers and divide by the total number of pixels in the feature. If both pixels are white (a value of 1) then 1 * 1 = 1. If both are black, then (-1) * (-1) = 1. Either way, every matching pixel results in a 1. Similarly, any mismatch is a -1. If all the pixels in a feature match, then adding them up and dividing by the total number of pixels gives a 1. Similarly, if none of the pixels in a feature match the image patch, then the answer is a -1.

 
To complete our convolution, we repeat this process, lining up the feature with every possible image patch. We can take the answer from each convolution and make a new two-dimensional array from it, based on where in the image each patch is located. This map of matches is also a filtered version of our original image. It’s a map of where in the image the feature is found. Values close to 1 show strong matches, values close to -1 show strong matches for the photographic negative of our feature, and values near zero show no match of any sort.

 
The next step is to repeat the convolution process in its entirety for each of the other features. The result is a set of filtered images, one for each of our filters. It’s convenient to think of this whole collection of convolution operations as a single processing step. In CNNs this is referred to as a convolution layer, hinting at the fact that it will soon have other layers added to it.

It’s easy to see how CNNs get their reputation as computation hogs. Although we can sketch our CNN on the back of a napkin, the number of additions, multiplications and divisions can add up fast. In math speak, they scale linearly with the number of pixels in the image, with the number of pixels in each feature and with the number of features. With so many factors, it’s easy to make this problem many millions of times larger without breaking a sweat. Small wonder that microchip manufacturers are now making specialized chips in an effort to keep up with the demands of CNNs.

#### Pooling
 
 We can think of max-pooling as a way for the network to ask whether a given feature is found anywhere in a region of the image. It then throws away the exact positional information. The intuition is that once a feature has been found, its exact location isn't as important as its rough location relative to other features. A big benefit is that there are many fewer pooled features, and so this helps reduce the number of parameters needed in later layers.

Max-pooling isn't the only technique used for pooling. Another common approach is known as L2 pooling. Here, instead of taking the maximum activation of a 2×22×2 region of neurons, we take the square root of the sum of the squares of the activations in the 2×22×2 region. While the details are different, the intuition is similar to max-pooling: L2 pooling is a way of condensing information from the convolutional layer. In practice, both techniques have been widely used. And sometimes people use other types of pooling operation. If you're really trying to optimize performance, you may use validation data to compare several different approaches to pooling, and choose the approach which works best. 



#### Local Receptive Fields

A small window which is sliding over the image matrix with a fixed stride.

#### Dropout

Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.


### Backpropagation

### The Backwards Pass

Our goal with backpropagation is to update each of the weights in the network so that they cause the actual output to be closer the target output, thereby minimizing the error for each output neuron and the network as a whole.

[Autograd](./autograd.ipynb) is an example of autograd in PyTorch.

[Backpropagation](./backpropagation.py) is a brief explanation of how gradients are calculated 


## Understanding the uses of Deep Learning


### Why do we need Deep Learning?
Emphatic use of Deep learning is in computer vision and image classification problems (recently NN have took over NLP/MT). Before jumping onto that, let's understand image classification and object detection. 

There is a great upsurge in computer vision field whose most typical applications are autonomous vehicles, smart video surveillance, facial detection and various people counting applications, fast and accurate object detection systems. These systems invole not only recognizing and classifying every object in an image, but localising each by drawing the appropriate bounding box and around it. This makes object detection a significantly harder task than it is trasitional computer vision predecessorr, image classification.

#### How do we practically use deep learning?
As professor Jason Brownlee suggests, there are eight different applications of deep learning. 

<strong>Objects classification in images:</strong>

Probably the most common use of deep learning. Involves image classification as well as object detection. 

<strong>Automatic Handwriting Generation</strong>

This is a task where given a corpus of handwriting examples, generate new handwriting for a given word or phrase.

The handwriting is provided as a sequence of coordinates used by a pen when the handwriting samples were created. From this corpus the relationship between the pen movement and the letters is learned and new examples can be generated ad hoc.

What is fascinating is that different styles can be learned and then mimicked. I would love to see this work combined with some forensic hand writing analysis expertise. 

<strong>Automatic Text Generation</strong>

This is an interesting task, where a corpus of text is learned and from this model new text is generated, word-by-word or character-by-character.

The model is capable of learning how to spell, punctuate, form sentiences and even capture the style of the text in the corpus.

Large recurrent neural networks are used to learn the relationship between items in the sequences of input strings and then generate text. More recently LSTM recurrent neural networks are demonstrating great success on this problem using a character-based model, generating one character at time.


#### Deep learning with GP-GPU programming.
Today's consumer CPUs have at most 8 cores. Server CPUs ranges from 4 to 24, and these cores support hyperthreading which can create 8 to 48 threads respectively. In neural network we apply almost same operations on different values of same array. Most of the operations that are computed in CPU can be run parallely and calculated independently then aggrerated thereafter. So we are optimizing this task,by using GP-GPU programming.  <br />
    This can be achieved by using libraries: <br />
        - OpenCL <br />
        - CUDA (device specific) <br /> 
        and many more...
    To refer a resources to practice parallel programming this [link](https://www.gitbook.com/book/leonardoaraujosantos/opencl/details) will be helpful. Only prerequisite is you must know MATLAB. <br />

If you are geek and want to know more about this.. refer [this](http://vertex.ai/blog/bringing-deep-learning-to-opencl). This link is specific to OpenCL. 

#### Additional Resources

- [Understand Neural Network](http://datathings.com/blog/post/neuralnet/)
- [Understand Convolutional Neural Network](https://brohrer.github.io/how_convolutional_neural_networks_work.html)

