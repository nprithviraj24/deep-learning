{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta:  (1, 10)\n",
      "dw shape:  (10, 10)\n",
      "W*Del shape:  (16, 1)\n",
      "new delta:  (1, 16)\n",
      "dw shape:  (32, 16)\n",
      "new delta:  (16, 32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (6,1) and (16,32) not aligned: 1 (dim 1) != 16 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-aac9f8b291cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m# print(np.shape(ypred), np.zeros(10))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;31m# mnist.loss.append(mnist.calcLoss(ypred, yt))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;31m# print(mnist.loss[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-aac9f8b291cc>\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, ypred, yact)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#         self.delta[L] = delta_cross_entropy(ypred,yact)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;31m#         L -= 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# #         print(\"shape delta:\", delta[l].shape, \" a shape: \", a[l-1].shape, \"  dW shape: \", dW[l].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rmul__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (6,1) and (16,32) not aligned: 1 (dim 1) != 16 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def RELU(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def relu_der(z):\n",
    "    return 1.*(z>0)\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "def softmax_der(x):\n",
    "    prob = softmax(x)\n",
    "#     print(np.shape(prob))\n",
    "    r = np.matmul(prob.T, (np.ones_like(prob)-prob))\n",
    "#     print(np.shape(r))\n",
    "    return r\n",
    "\n",
    "def oneHotEncode(y,softmaxClasses):\n",
    "        yactual = np.matrix(np.zeros(softmaxClasses)).T\n",
    "        yactual[y] = 1\n",
    "        return yactual    \n",
    "    \n",
    "def crossEntropy(ypred,y,softmaxClasses):\n",
    "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    #one hot encode\n",
    "    yactual = oneHotEncode(y,softmaxClasses)\n",
    "    l = np.log(ypred)\n",
    "    return -np.sum(l*yactual)\n",
    "#     logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
    "#     xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "#     return xentropy\n",
    "    \n",
    "\n",
    "def delta_cross_entropy(y, X):\n",
    "          m = y.shape[0]\n",
    "          grad = softmax(X)\n",
    "          idx = np.where(grad == y*grad)\n",
    "          grad[idx] = grad[idx] - 1\n",
    "          grad = grad/m\n",
    "          return grad\n",
    "\n",
    "\n",
    "\n",
    "class neuralNetwork():    \n",
    "    FCreluLayers = 0  \n",
    "    Weights = []\n",
    "    Biases = []\n",
    "    softmax = False\n",
    "    softmaxClasses = 0\n",
    "    loss = []\n",
    "    delta = [[]];    dW = [[]];    db = [[]]\n",
    "    act = []\n",
    "    logits = []\n",
    "    def FullyConnectedreluLayers(self, values):\n",
    "        assert len(values) == self.FCreluLayers+1, \"Number of fully connected layers are not the same.\"\n",
    "        self.Weights.append([])\n",
    "        self.Biases.append([])\n",
    "        for i in range(1, self.FCreluLayers+1):            \n",
    "            self.Weights.append(np.random.normal(0, 0.1, ([values[i-1], values[i]])))\n",
    "            self.Biases.append(np.random.normal(0, 0.1, ([values[i], 1])))\n",
    "            self.delta.append([]);    self.dW.append([]);    self.db.append([])\n",
    "#             print(type(self.Weights[i]))   \n",
    "    \n",
    "    def softmaxLayer(self):\n",
    "        previous = self.Weights[-1].shape[1]\n",
    "        self.Weights.append(np.random.normal(0,0.1,[previous, self.softmaxClasses]))\n",
    "        self.Biases.append(np.random.normal(0, 0.1, (self.softmaxClasses, 1)))\n",
    "        self.delta.append([]);    self.dW.append([]);    self.db.append([])\n",
    "        \n",
    "    def calcLoss(ypred, yactual):\n",
    "        if self.softmax == True:\n",
    "            return crossEntropy(ypred,yactual, self.softmaxClasses)\n",
    "    \n",
    "    def feedForward(self,X):\n",
    "#         a = []\n",
    "        self.act.append(X.T)\n",
    "#         l = self.FCLayers if softmax == False else self.FCLayers-1\n",
    "        \n",
    "        for i in range(1, self.FCreluLayers+1):\n",
    "#             print(\" weights shape: \", np.shape(self.Weights[i].T) , \"a shape: \", np.shape(self.act[i-1]))\n",
    "            self.logits.append(np.matmul(self.Weights[i].T, self.act[i-1]) + self.Biases[i])\n",
    "            self.act.append( RELU(self.logits[-1]) )\n",
    "            \n",
    "#         print(\"-----\")\n",
    "        if self.softmax == True:\n",
    "            self.logits.append(np.matmul(self.Weights[-1].T, self.act[-1]) + self.Biases[-1])\n",
    "            self.act.append(softmax(self.logits[-1]))\n",
    "#             print(np.sum(self.act[-1]))   \n",
    "#             print(self.act[-1])\n",
    "        return self.act[-1]\n",
    "    \n",
    "    def backprop(self, ypred, yact):\n",
    "        L = 3       \n",
    "        self.delta[L] = delta_cross_entropy(ypred,yact)\n",
    "        print(\"delta: \", np.shape(self.delta[L]))\n",
    "        self.db[L] = self.delta[L].copy()\n",
    "        self.dW[L] = self.act[-1] * self.delta[L]\n",
    "        print(\"dw shape: \", np.shape(self.dW[L]))\n",
    "        asd = self.Weights[L] * self.delta[L].T\n",
    "        print(\"W*Del shape: \", np.shape(asd))\n",
    "        self.delta[L-1] = np.multiply(softmax_der(self.logits[L-1]), asd.T)\n",
    "        print(\"new delta: \", np.shape(self.delta[L-1]))\n",
    "        L -= 1        \n",
    "#         self.delta[L] = delta_cross_entropy(ypred,yact)\n",
    "        self.db[L] = self.delta[L].copy()\n",
    "        self.dW[L] = self.act[L-1] * self.delta[L]\n",
    "        print(\"dw shape: \", np.shape(self.dW[L]))\n",
    "        bsd = np.matmul(self.Weights[L],self.delta[L].T)\n",
    "        self.delta[L-1] = np.multiply(relu_der(self.logits[L-1]), bsd.T)\n",
    "        print(\"new delta: \", np.shape(self.delta[L-1]))\n",
    "        L -= 1        \n",
    "#         self.delta[L] = delta_cross_entropy(ypred,yact)\n",
    "        self.db[L] = self.delta[L].copy()\n",
    "        self.dW[L] = self.act[L-1] * self.delta[L]\n",
    "#         L -= 1\n",
    "# #         print(\"shape delta:\", delta[l].shape, \" a shape: \", a[l-1].shape, \"  dW shape: \", dW[l].shape)\n",
    "#         if l > 1:\n",
    "#             print(\"W[l] shape: \", W[l].shape)\n",
    "#             delta[l-1] = np.multiply(actder(z[l-1]), W[l] * delta[l])\n",
    "#         return a[-1]\n",
    "#         return [np.shape(self.Weights[i]) for i in range(len(self.Weights))]\n",
    "        for l in range(1,len(self.Weights)):            \n",
    "            W[l] = W[l] - alpha * dW[l]\n",
    "            b[l] = b[l] - alpha * db[l]\n",
    "\n",
    "\n",
    "mnist = neuralNetwork()\n",
    "mnist.__class__.FCreluLayers = 2 #exclusing the softmax\n",
    "mnist.__class__.softmax = True\n",
    "mnist.__class__.softmaxClasses = 10\n",
    "N = 6\n",
    "h1 = 32\n",
    "h2 = 16\n",
    "mnist.FullyConnectedreluLayers([N,h1,h2])\n",
    "mnist.softmaxLayer()\n",
    "\n",
    "ypred = mnist.feedForward( np.matrix([0,1,2,3,4,5]) )\n",
    "# print(np.shape(ypred), np.zeros(10))\n",
    "mnist.backprop(ypred, np.matrix(np.zeros(10)) )\n",
    "# mnist.loss.append(mnist.calcLoss(ypred, yt))\n",
    "# print(mnist.loss[-1])\n",
    "\n",
    "# print([np.shape(mnist.Weights[i]) for i in range(len(mnist.Weights))])  \n",
    "# print(mnist.feedForward(np.matrix([0,1,2,3,4,5]), 3 ))\n",
    "# mnist.layerWeights[-1].shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_digits\n",
    "# digits = load_digits()\n",
    "# print(\"listing digits: \", list(digits))\n",
    "# print(\"Number of samples: \", digits.data.shape[0])\n",
    "# print(\"Size of each sample: \", digits.data.shape[1])\n",
    "# print(\"Listing target names: \", list(digits.target_names))\n",
    "\n",
    "# y = np.matrix(digits.target).T\n",
    "# X = np.matrix(digits.data)\n",
    "# print(\"Image at index 3: \")\n",
    "# import matplotlib.pyplot as plt \n",
    "# plt.matshow(digits.images[3]) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# r = np.array([1,0,0])\n",
    "# logits = np.array([0.6,0,0.5])\n",
    "# logits_for_answers = logits[np.arange(len(logits)),r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.matrix(np.zeros(5)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "[0.47000363 1.22377543 0.33647224 1.38629436]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.08411805915530322"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oneHotEncode(y,softmaxClasses):\n",
    "        yactual = np.matrix(np.zeros(softmaxClasses)).T\n",
    "        yactual[y] = 1\n",
    "        return yactual\n",
    "    \n",
    "def crossEntropy(ypred,y,softmaxClasses):\n",
    "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    #one hot encode\n",
    "    yactual = oneHotEncode(y,softmaxClasses)\n",
    "    print(yactual)\n",
    "    l = np.log(ypred)\n",
    "    print(l)\n",
    "    return - np.sum(l*yactual)/yactual.shape[0]\n",
    "\n",
    "crossEntropy(np.array([1.6,3.4,1.4,4]), 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.08279633e-05,  8.37990924e-05,  2.49801574e-01, -2.49916201e-01])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delta_cross_entropy(y, X):\n",
    "          m = y.shape[0]\n",
    "          grad = softmax(X)\n",
    "          idx = np.where(grad == y*grad)\n",
    "          grad[idx] = grad[idx] - 1\n",
    "          grad = grad/m\n",
    "          return grad\n",
    "delta_cross_entropy(np.array([4,3,2,1]), np.array([3,4,12,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
