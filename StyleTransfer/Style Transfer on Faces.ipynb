{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Style Transfer on Face Images\n",
    "\n",
    "By [Prithvi Raju](nprithviraj24@gmail.com) <br /> <br />\n",
    "\n",
    "<break>\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "This Jupyter-notebook will discuss the methodology, which is not an original solution but encompasses my understanding of complications involved on Style transfer applied on faces, and way(s) to mitigate it.\n",
    "\n",
    "##### NOTE: This notebook assumes that you are already familiar with Style Transfer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Style Transfer on Face:\n",
    " <break>\n",
    " <break>\n",
    "     \n",
    "   Figure 1\n",
    "![Style Transfer](style-transfer-on-face.png )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges in such type of Neural Style Transfer: \n",
    "    \n",
    "    - Photo realism \n",
    "    - Semantic consistency.\n",
    "\n",
    "The vanilla Style Transfer proposed by Gatys (2015) works perfectly on artistic image, but it fails to modify or synthesize realistic facial neural transfer as shown in the Figure 1. Style Trasnfer uses something called Gram matrix that is great for artistic purposes, but it suffers when we want to have some control over which textures are transferred to each part of the result. The reason behind this is it destroys the semantics of the style image, only preserving the basic texture components.  Human vision is very sensitive to facial irregularities and even small distortions can make a face look unrealistic.\n",
    "\n",
    "Facial texture comprises skin texture details like wrinkles, pigmentation and pores, while facial structure consists of the meso-structures such as eyes, nose, mouth and face shape. Following example image shows the problems of style transfer applied on face, where the content image (Jim Carrey) and style image (Sm√©agol). The problem is even as the meso-structures from style image is contributing to the output image as well. In a way, this is not a good example of style transfer, where final output is not pleasing or adequate result.\n",
    "\n",
    "![Meso-structure](meso-structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation details:  <br />\n",
    "\n",
    "#### 1. Facial Semantic Regularization\n",
    " As discussed in the previous cell, the whole problem must be divided into two different solvable steps. One of them is to preserve the facial prior from the content image i.e. Facial Prior Regularization which ensures that there must be no changes to meso-structure of the face (content image) when it is trying to incorporate style from another image (style image). But this alone doesn't ensure that identity will be preserved, aditionally, during the training process we calculate Facial Semantic Structure Loss that tackles the challenge of preserving facial shape by minimizing a Facial Structure Loss which we define as an identity loss from a pre-trained face recognition network (VGG-Face) that implicitly preserves the facial structure. <br />\n",
    "\n",
    "\n",
    "###### Facial Semantic Structure Loss\n",
    "\n",
    "The idea is that we have to preserve the meso-structure of content image, and this is done using pretrained network VGG-Face. The mid level features (from VGG-Face) of an image captures the essence of only meso-structures of the given input face image, and then we minimize these representations with the one we want it to share the same representations. In a way we are enforcing the network to produce the same meso-structure as the content image, as VGG-Face's mid-level representations only captures the shapes and not the texture of the input face image.\n",
    "\n",
    "#### 2. Enforcing style selection and localization.\n",
    "\n",
    " We have to nullify Gram Matrix as an option to synthesize style for output image because it gives global impact to the ouput image, instead we will have to look for other option such as CNN in MGAN that is ideal for preserving local textural structures. However, it also carries the semantic information from the style image, which violates the goal of preserving facial identity (discussed in previous point). For this, we augment the VGG-19 (used in MRF-CNN) framework with Facial semantic regularization.\n",
    "\n",
    "#### Summarizing\n",
    "\n",
    "In a nutshell, Facial identity is preserved using Facial Semantic Regularization, which regularizes the update of meso-structures using a facial prior and facial semantic structural loss. Texture loss regularizes the update of local textures from the style image. The output image is initialized with the content image and updated at each iteration by back-propagating the error gradients for the combined losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions inspired from Original Paper (FaceText)\n",
    "\n",
    "###### Facial Prior Regularization\n",
    "\n",
    "Inspired by the dropout regularization which randomly dropssome units and blocks the gradient during the optimization, we build a facial prior regularization that smoothly slows down the updating around the meso-structures. For generating the facial prior mask,we follow the prior work to generate 66 landmark points and draw contours for meso-structures. Then we build a landmark mask by applying a Gaussian blur to the facial contour and normalizethe output between 0 and 1, which provides a smooth transition between meso-structures and rest ofthe face. For implementation, we build a CNN layer that performs an identity mapping during theforward pass of the optimization, and scales the gradient with an element-wise product with the faceprior mask during back-propagation.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture  (From FaceTex)\n",
    "\n",
    "![FaceTex](FaceTex.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please Note This methodology is understood from the original paper [FaceTex](https://arxiv.org/pdf/1706.04306.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
